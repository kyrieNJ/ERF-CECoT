## LLM Inference
This project uses the LLaMA-Factory framework. For detailed installation and usage instructions, please refer to: [link](hub.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md).

## Prompt Template
For details on the empathic response prompt template used by LLM in this project, please refer to the Response Generation Module section of the paper.

